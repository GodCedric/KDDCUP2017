{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split_RF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017-05-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta,date,time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 平均时间\n",
    "A2_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/A2_train_data.csv')\n",
    "A3_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/A3_train_data.csv')\n",
    "B1_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/B1_train_data.csv')\n",
    "B3_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/B3_train_data.csv')\n",
    "C1_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/C1_train_data.csv')\n",
    "C3_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/C3_train_data.csv')\n",
    "\n",
    "A2_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/A2_test_data.csv')\n",
    "A3_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/A3_test_data.csv')\n",
    "B1_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/B1_test_data.csv')\n",
    "B3_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/B3_test_data.csv')\n",
    "C1_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/C1_test_data.csv')\n",
    "C3_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/C3_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 流量\n",
    "V10_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V10_train_data.csv')\n",
    "V11_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V11_train_data.csv')\n",
    "V20_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V20_train_data.csv')\n",
    "V30_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V30_train_data.csv')\n",
    "V31_train_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V31_train_data.csv')\n",
    "\n",
    "V10_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V10_test_data.csv')\n",
    "V11_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V11_test_data.csv')\n",
    "V20_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V20_test_data.csv')\n",
    "V30_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V30_test_data.csv')\n",
    "V31_test_data = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/训练数据/分割_非独热_非量化天气/V31_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分离特征 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A2_label = A2_train_data.avg_travel_time\n",
    "A2_train_data = A2_train_data.drop(['avg_travel_time'], axis=1)\n",
    "\n",
    "A3_label = A3_train_data.avg_travel_time\n",
    "A3_train_data = A3_train_data.drop(['avg_travel_time'], axis=1)\n",
    "\n",
    "B1_label = B1_train_data.avg_travel_time\n",
    "B1_train_data = B1_train_data.drop(['avg_travel_time'], axis=1)\n",
    "\n",
    "B3_label = B3_train_data.avg_travel_time\n",
    "B3_train_data = B3_train_data.drop(['avg_travel_time'], axis=1)\n",
    "\n",
    "C1_label = C1_train_data.avg_travel_time\n",
    "C1_train_data = C1_train_data.drop(['avg_travel_time'], axis=1)\n",
    "\n",
    "C3_label = C3_train_data.avg_travel_time\n",
    "C3_train_data = C3_train_data.drop(['avg_travel_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V10_label = V10_train_data.volume\n",
    "V10_train_data = V10_train_data.drop(['volume'], axis=1)\n",
    "\n",
    "V11_label = V11_train_data.volume\n",
    "V11_train_data = V11_train_data.drop(['volume'], axis=1)\n",
    "\n",
    "V20_label = V20_train_data.volume\n",
    "V20_train_data = V20_train_data.drop(['volume'], axis=1)\n",
    "\n",
    "V30_label = V30_train_data.volume\n",
    "V30_train_data = V30_train_data.drop(['volume'], axis=1)\n",
    "\n",
    "V31_label = V31_train_data.volume\n",
    "V31_train_data = V31_train_data.drop(['volume'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 自定义评分函数\n",
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "score = make_scorer(MAPE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "# 对n_estimators进行网格搜索  \n",
    "param_test1= {'n_estimators':range(30,150,10),'max_depth':range(3,8,1)}\n",
    "base_estimator = RandomForestRegressor(random_state=2017)\n",
    "gsearch1= GridSearchCV(estimator = base_estimator, param_grid =param_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(C1_train_data, C1_label)\n",
    "\n",
    "# 输出最优参数\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19014696 -0.22320834 -0.21076194 -0.18623772 -0.19900119]\n"
     ]
    }
   ],
   "source": [
    "# 看下cv结果\n",
    "rf_base = RandomForestRegressor(n_estimators = 90, max_depth = 6, oob_score = True, random_state = 10)\n",
    "test_score = cross_val_score(rf_base, A2_train_data, A2_label, cv=5, scoring=score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_estimators = 91           #增加子模型数可降低整体模型方差，对子模型的方差偏差无影响，模型的准确度会随着“子模型数”的增加而提高，但准确度的提高有一个上限\n",
    "#max_leaf_nodes =              #最大叶节点数\n",
    "#max_depth = 5                  #最大树深度（叶节点越多或者树越深，意味着子模型的偏差越低，方差越高）\n",
    "#min_samples_split =           #分裂所需最小样本数   \n",
    "#min_samples_leaf =            #叶节点最小样本数\n",
    "#min_weight_fraction_leaf =    #叶节点最小权重总值(分裂所需样本数越少或者叶节点所需样本越少，也意味着子模型越复杂)\n",
    "#bootstrap =                   #对样本进行子采样来降低子模型之间的关联度，从而降低整体模型的方差\n",
    "#max_features =                #适当地减少“分裂时考虑的最大特征数”,给子模型注入了另外的随机性，同样也达到了降低子模型之间关联度的效果。(但是一味地降低该参数也是不行的，因为分裂时可选特征变少，模型的偏差会越来越大。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18917322 -0.21996765 -0.20406052 -0.18766663 -0.19744673]\n"
     ]
    }
   ],
   "source": [
    "rf_base1 = RandomForestRegressor(n_estimators = 90, max_depth = 5, oob_score = True, random_state = 10)\n",
    "test_score = cross_val_score(rf_base1, A2_train_data, A2_label, cv=5, scoring=score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A2\n",
    "rf_base2 = RandomForestRegressor(n_estimators = 50, max_depth = 3, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base2.fit(A3_train_data, A3_label)\n",
    "A3_test_data['avg_travel_time'] = rf_base1.predict(A3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base3 = RandomForestRegressor(n_estimators = 140, max_depth = 5, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base3.fit(B1_train_data, B1_label)\n",
    "B1_test_data['avg_travel_time'] = rf_base1.predict(B1_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(B1_train_data, B1_label)\n",
    "B1_test_data['avg_travel_time'] = rf_base1.predict(B1_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(B3_train_data, B3_label)\n",
    "B3_test_data['avg_travel_time'] = rf_base1.predict(B3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(C1_train_data, C1_label)\n",
    "C1_test_data['avg_travel_time'] = rf_base1.predict(C1_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(C3_train_data, C3_label)\n",
    "C3_test_data['avg_travel_time'] = rf_base1.predict(C3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(V10_train_data, V10_label)\n",
    "V10_test_data['volume'] = rf_base1.predict(V10_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(V11_train_data, V11_label)\n",
    "V11_test_data['volume'] = rf_base1.predict(V11_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(V20_train_data, V20_label)\n",
    "V20_test_data['volume'] = rf_base1.predict(V20_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(V30_train_data, V30_label)\n",
    "V30_test_data['volume'] = rf_base1.predict(V30_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_base1.fit(V31_train_data, V31_label)\n",
    "V31_test_data['volume'] = rf_base1.predict(V31_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travel_time_submission = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/submission_sample/travel_time_submission.csv')\n",
    "volume_submission = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/submission_sample/volume_submission.csv')\n",
    "\n",
    "temp1 = pd.concat([A2_test_data, A3_test_data, B1_test_data, B3_test_data, C1_test_data, C3_test_data], axis=0)\n",
    "temp2 = pd.concat([V10_test_data, V11_test_data, V20_test_data, V30_test_data, V31_test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = np.array(temp1.avg_travel_time)\n",
    "travel_time_submission['avg_travel_time'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
