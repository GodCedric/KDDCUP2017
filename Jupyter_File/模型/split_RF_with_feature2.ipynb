{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split_RF_with_feature2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017-05-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta,date,time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 录入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travel_time_train = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/final_data/加工好的数据/7.75/travel_time_train_data.csv')\n",
    "volume_train = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/final_data/加工好的数据/7.75/volume_train_data.csv')\n",
    "\n",
    "test_travel_time = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/final_data/加工好的数据/7.75/test_travel_time_data.csv')\n",
    "test_volume = pd.read_csv('/home/godcedric/GitLocal/KDDCUP2017/final_data/加工好的数据/7.75/test_volume_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割路径，对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A2_train = travel_time_train[travel_time_train['route'] == 'A-2']\n",
    "A3_train = travel_time_train[travel_time_train['route'] == 'A-3']\n",
    "B1_train = travel_time_train[travel_time_train['route'] == 'B-1']\n",
    "B3_train = travel_time_train[travel_time_train['route'] == 'B-3']\n",
    "C1_train = travel_time_train[travel_time_train['route'] == 'C-1']\n",
    "C3_train = travel_time_train[travel_time_train['route'] == 'C-3']\n",
    "\n",
    "A2_test = test_travel_time[test_travel_time['route'] == 'A-2']\n",
    "A3_test = test_travel_time[test_travel_time['route'] == 'A-3']\n",
    "B1_test = test_travel_time[test_travel_time['route'] == 'B-1']\n",
    "B3_test = test_travel_time[test_travel_time['route'] == 'B-3']\n",
    "C1_test = test_travel_time[test_travel_time['route'] == 'C-1']\n",
    "C3_test = test_travel_time[test_travel_time['route'] == 'C-3']\n",
    "\n",
    "V10_train =  volume_train[volume_train['pair'] == '1-0']\n",
    "V11_train =  volume_train[volume_train['pair'] == '1-1']\n",
    "V20_train =  volume_train[volume_train['pair'] == '2-0']\n",
    "V30_train =  volume_train[volume_train['pair'] == '3-0']\n",
    "V31_train =  volume_train[volume_train['pair'] == '3-1']\n",
    "\n",
    "V10_test =  test_volume[test_volume['pair'] == '1-0']\n",
    "V11_test =  test_volume[test_volume['pair'] == '1-1']\n",
    "V20_test =  test_volume[test_volume['pair'] == '2-0']\n",
    "V30_test =  test_volume[test_volume['pair'] == '3-0']\n",
    "V31_test =  test_volume[test_volume['pair'] == '3-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_columns = ['avg_travel_time', 'is_true',\n",
    "                'month', 'day', 'weekday','holiday','timemap', \n",
    "                'pressure', 'sea_pressure', 'wind_direction', 'wind_speed', 'temperature',\n",
    "                'rel_humidity', 'precipitation', \n",
    "                'last_20min_A2', 'last_20min_A3', 'last_20min_B1', 'last_20min_B3', 'last_20min_C1',\n",
    "                'last_20min_C3', 'last_20min_V10', 'last_20min_V11', 'last_20min_V20',\n",
    "                'last_20min_V30', 'last_20min_V31'\n",
    "               ]\n",
    "\n",
    "time_columns2 = ['month', 'day', 'weekday','holiday','timemap', \n",
    "                'pressure', 'sea_pressure', 'wind_direction', 'wind_speed', 'temperature',\n",
    "                'rel_humidity', 'precipitation', \n",
    "                'last_20min_A2', 'last_20min_A3', 'last_20min_B1', 'last_20min_B3', 'last_20min_C1',\n",
    "                'last_20min_C3', 'last_20min_V10', 'last_20min_V11', 'last_20min_V20',\n",
    "                'last_20min_V30', 'last_20min_V31'\n",
    "                ]\n",
    "\n",
    "volume_columns = ['volume', 'is_true',\n",
    "                  'month', 'day', 'weekday', 'holiday', 'timemap', \n",
    "                  'pressure', 'sea_pressure','wind_direction', 'wind_speed', 'temperature', \n",
    "                  'rel_humidity', 'precipitation', \n",
    "                  'last_20min_A2', 'last_20min_A3', 'last_20min_B1', 'last_20min_B3', 'last_20min_C1', 'last_20min_C3',\n",
    "                  'last_20min_V10', 'last_20min_V11', 'last_20min_V20', 'last_20min_V30',\n",
    "                  'last_20min_V31'\n",
    "                 ]\n",
    "\n",
    "volume_columns2 = ['month', 'day', 'weekday', 'holiday', 'timemap', \n",
    "                  'pressure', 'sea_pressure','wind_direction', 'wind_speed', 'temperature', \n",
    "                  'rel_humidity', 'precipitation', \n",
    "                  'last_20min_A2', 'last_20min_A3', 'last_20min_B1', 'last_20min_B3', 'last_20min_C1', 'last_20min_C3',\n",
    "                  'last_20min_V10', 'last_20min_V11', 'last_20min_V20', 'last_20min_V30',\n",
    "                  'last_20min_V31'\n",
    "                  ]\n",
    "\n",
    "A2_train = A2_train[time_columns]\n",
    "A3_train = A3_train[time_columns]\n",
    "B1_train = B1_train[time_columns]\n",
    "B3_train = B3_train[time_columns]\n",
    "C1_train = C1_train[time_columns]\n",
    "C3_train = C3_train[time_columns]\n",
    "\n",
    "A2_test = A2_test[time_columns2]\n",
    "A3_test = A3_test[time_columns2]\n",
    "B1_test = B1_test[time_columns2]\n",
    "B3_test = B3_test[time_columns2]\n",
    "C1_test = C1_test[time_columns2]\n",
    "C3_test = C3_test[time_columns2]\n",
    "\n",
    "V10_train =  V10_train[volume_columns]\n",
    "V11_train =  V11_train[volume_columns]\n",
    "V20_train =  V20_train[volume_columns]\n",
    "V30_train =  V30_train[volume_columns]\n",
    "V31_train =  V31_train[volume_columns]\n",
    "\n",
    "V10_test =  V10_test[volume_columns2]\n",
    "V11_test =  V11_test[volume_columns2]\n",
    "V20_test =  V20_test[volume_columns2]\n",
    "V30_test =  V30_test[volume_columns2]\n",
    "V31_test =  V31_test[volume_columns2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 自定义评分函数\n",
    "def MAPE2(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "score = make_scorer(MAPE2, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "A2_train_true = A2_train[A2_train['is_true'] == True]\n",
    "A2_train_false = A2_train[A2_train['is_true'] == False]\n",
    "\n",
    "del A2_train['is_true']\n",
    "del A2_train_true['is_true']\n",
    "del A2_train_false['is_true']\n",
    "\n",
    "# 对n_estimators进行网格搜索  \n",
    "param_test1= {'n_estimators':range(30,150,10),'max_depth':range(3,8,1)}\n",
    "base_estimator = RandomForestRegressor(random_state=2017)\n",
    "gsearch1= GridSearchCV(estimator = base_estimator, param_grid =param_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(A2_train_true.iloc[:,1:], A2_train_true.iloc[:,0],)\n",
    "\n",
    "# 输出最优参数\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19519906 -0.19894496 -0.1955828  -0.18828745 -0.17990259]\n"
     ]
    }
   ],
   "source": [
    "rf_base = RandomForestRegressor(n_estimators = 100, max_depth = 5, oob_score = True, random_state = 21)\n",
    "test_score = cross_val_score(rf_base, A2_train_true.iloc[:,1:], A2_train_true.iloc[:,0], cv=5, scoring=score)\n",
    "print(test_score)\n",
    "\n",
    "# A2\n",
    "rf_base1 = RandomForestRegressor(n_estimators = 100, max_depth = 5, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base1.fit(A2_train.iloc[:,1:], A2_train.iloc[:,0],)\n",
    "A2time_predict = rf_base1.predict(A2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "A3_train_true = A3_train[A3_train['is_true'] == True]\n",
    "A3_train_false = A3_train[A3_train['is_true'] == False]\n",
    "\n",
    "del A3_train['is_true']\n",
    "del A3_train_true['is_true']\n",
    "del A3_train_false['is_true']\n",
    "\n",
    "# 对n_estimators进行网格搜索  \n",
    "param_test1= {'n_estimators':range(30,150,10),'max_depth':range(3,8,1)}\n",
    "base_estimator = RandomForestRegressor(random_state=2017)\n",
    "gsearch1= GridSearchCV(estimator = base_estimator, param_grid =param_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(A3_train_true.iloc[:,1:], A3_train_true.iloc[:,0],)\n",
    "\n",
    "# 输出最优参数\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19799819 -0.18629371 -0.1795421  -0.19004362 -0.15903653]\n"
     ]
    }
   ],
   "source": [
    "rf_base = RandomForestRegressor(n_estimators = 100, max_depth = 4, oob_score = True, random_state = 21)\n",
    "test_score = cross_val_score(rf_base, A3_train_true.iloc[:,1:], A3_train_true.iloc[:,0], cv=5, scoring=score)\n",
    "print(test_score)\n",
    "\n",
    "# A2\n",
    "rf_base2 = RandomForestRegressor(n_estimators = 100, max_depth = 4, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base2.fit(A3_train.iloc[:,1:], A3_train.iloc[:,0],)\n",
    "A3time_predict = rf_base2.predict(A3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "B1_train_true = B1_train[B1_train['is_true'] == True]\n",
    "B1_train_false = B1_train[B1_train['is_true'] == False]\n",
    "\n",
    "del B1_train['is_true']\n",
    "del B1_train_true['is_true']\n",
    "del B1_train_false['is_true']\n",
    "\n",
    "# 对n_estimators进行网格搜索  \n",
    "param_test1= {'n_estimators':range(30,150,10),'max_depth':range(3,8,1)}\n",
    "base_estimator = RandomForestRegressor(random_state=2017)\n",
    "gsearch1= GridSearchCV(estimator = base_estimator, param_grid =param_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(B1_train_true.iloc[:,1:], B1_train_true.iloc[:,0],)\n",
    "\n",
    "# 输出最优参数\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17331517 -0.1671349  -0.19010221 -0.1863068  -0.19740437]\n"
     ]
    }
   ],
   "source": [
    "rf_base = RandomForestRegressor(n_estimators = 40, max_depth = 4, oob_score = True, random_state = 21)\n",
    "test_score = cross_val_score(rf_base, B1_train_true.iloc[:,1:], B1_train_true.iloc[:,0], cv=5, scoring=score)\n",
    "print(test_score)\n",
    "\n",
    "# A2\n",
    "rf_base3 = RandomForestRegressor(n_estimators = 40, max_depth = 4, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base3.fit(B1_train.iloc[:,1:], B1_train.iloc[:,0],)\n",
    "B1time_predict = rf_base3.predict(B1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "B3_train_true = B3_train[B3_train['is_true'] == True]\n",
    "B3_train_false = B3_train[B3_train['is_true'] == False]\n",
    "\n",
    "del B3_train['is_true']\n",
    "del B3_train_true['is_true']\n",
    "del B3_train_false['is_true']\n",
    "\n",
    "# 对n_estimators进行网格搜索  \n",
    "param_test1= {'n_estimators':range(30,150,10),'max_depth':range(3,8,1)}\n",
    "base_estimator = RandomForestRegressor(random_state=2017)\n",
    "gsearch1= GridSearchCV(estimator = base_estimator, param_grid =param_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(B3_train_true.iloc[:,1:], B3_train_true.iloc[:,0],)\n",
    "\n",
    "# 输出最优参数\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22074096 -0.22483231 -0.2327173  -0.25059284 -0.2238264 ]\n"
     ]
    }
   ],
   "source": [
    "rf_base = RandomForestRegressor(n_estimators = 70, max_depth = 3, oob_score = True, random_state = 21)\n",
    "test_score = cross_val_score(rf_base, B3_train_true.iloc[:,1:], B3_train_true.iloc[:,0], cv=5, scoring=score)\n",
    "print(test_score)\n",
    "\n",
    "# A2\n",
    "rf_base4 = RandomForestRegressor(n_estimators = 70, max_depth = 3, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base4.fit(B3_train.iloc[:,1:], B3_train.iloc[:,0],)\n",
    "B3time_predict = rf_base4.predict(B3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'n_estimators': 110}\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "C1_train_true = C1_train[C1_train['is_true'] == True]\n",
    "C1_train_false = C1_train[C1_train['is_true'] == False]\n",
    "\n",
    "del C1_train['is_true']\n",
    "del C1_train_true['is_true']\n",
    "del C1_train_false['is_true']\n",
    "\n",
    "# 对n_estimators进行网格搜索  \n",
    "param_test1= {'n_estimators':range(30,150,10),'max_depth':range(3,8,1)}\n",
    "base_estimator = RandomForestRegressor(random_state=2017)\n",
    "gsearch1= GridSearchCV(estimator = base_estimator, param_grid =param_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(C1_train_true.iloc[:,1:], C1_train_true.iloc[:,0],)\n",
    "\n",
    "# 输出最优参数\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17142684 -0.16737456 -0.17063259 -0.16065334 -0.16765459]\n"
     ]
    }
   ],
   "source": [
    "rf_base = RandomForestRegressor(n_estimators = 110, max_depth = 5, oob_score = True, random_state = 21)\n",
    "test_score = cross_val_score(rf_base, C1_train_true.iloc[:,1:], C1_train_true.iloc[:,0], cv=5, scoring=score)\n",
    "print(test_score)\n",
    "\n",
    "# A2\n",
    "rf_base5 = RandomForestRegressor(n_estimators = 110, max_depth = 5, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base5.fit(C1_train.iloc[:,1:], C1_train.iloc[:,0],)\n",
    "C1time_predict = rf_base5.predict(C1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'n_estimators': 60}\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "C3_train_true = C3_train[C3_train['is_true'] == True]\n",
    "C3_train_false = C3_train[C3_train['is_true'] == False]\n",
    "\n",
    "del C3_train['is_true']\n",
    "del C3_train_true['is_true']\n",
    "del C3_train_false['is_true']\n",
    "\n",
    "# 对n_estimators进行网格搜索  \n",
    "param_test1= {'n_estimators':range(30,150,10),'max_depth':range(3,8,1)}\n",
    "base_estimator = RandomForestRegressor(random_state=2017)\n",
    "gsearch1= GridSearchCV(estimator = base_estimator, param_grid =param_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(C3_train_true.iloc[:,1:], C3_train_true.iloc[:,0],)\n",
    "\n",
    "# 输出最优参数\n",
    "print(gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20130094 -0.22153468 -0.20369048 -0.21665602 -0.24365605]\n"
     ]
    }
   ],
   "source": [
    "rf_base = RandomForestRegressor(n_estimators = 60, max_depth = 3, oob_score = True, random_state = 21)\n",
    "test_score = cross_val_score(rf_base, C3_train_true.iloc[:,1:], C3_train_true.iloc[:,0], cv=5, scoring=score)\n",
    "print(test_score)\n",
    "\n",
    "# A2\n",
    "rf_base6 = RandomForestRegressor(n_estimators = 110, max_depth = 5, oob_score = True, random_state = 10)\n",
    "\n",
    "rf_base6.fit(C3_train.iloc[:,1:], C3_train.iloc[:,0],)\n",
    "C3time_predict = rf_base6.predict(C3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/godcedric/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "submission_travel_time = test_travel_time[['intersection_id','tollgate_id','time_window']]\n",
    "predict_result = np.concatenate([A2time_predict,A3time_predict,B1time_predict,B3time_predict,C1time_predict,C3time_predict], axis=0)\n",
    "submission_travel_time['avg_travel_time'] = predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_travel_time.to_csv('/home/godcedric/GitLocal/KDDCUP2017/submission_result/phase2.5/RF/travel_time_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
